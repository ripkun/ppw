{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00267db",
   "metadata": {},
   "source": [
    "# Crawling Berita Kompas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea435468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, uuid, time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse, urlunparse\n",
    "import pandas as pd\n",
    "\n",
    "# Header untuk menyamarkan request agar dianggap seperti browser biasa\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc2337c",
   "metadata": {},
   "source": [
    "# Daftar Kategori berita yang akan di crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910ab210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambah kategori supaya data lebih banyak\n",
    "category_urls = {\n",
    "    \"Nasional\": \"https://nasional.kompas.com/\",\n",
    "    \"Ekonomi\": \"https://money.kompas.com/\",\n",
    "    \"Tekno\": \"https://tekno.kompas.com/\",\n",
    "    \"Otomotif\": \"https://otomotif.kompas.com/\",\n",
    "    \"Health\": \"https://health.kompas.com/\",\n",
    "    \"Edukasi\": \"https://edukasi.kompas.com/\",\n",
    "    \"Bola\": \"https://bola.kompas.com/\",\n",
    "    \"Entertainment\": \"https://entertainment.kompas.com/\",\n",
    "    \"Lifestyle\": \"https://lifestyle.kompas.com/\",\n",
    "    \"Travel\": \"https://travel.kompas.com/\",\n",
    "    \"Internasional\": \"https://internasional.kompas.com/\",\n",
    "    \"Properti\": \"https://properti.kompas.com/\",\n",
    "    \"Sains\": \"https://sains.kompas.com/\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc192e25",
   "metadata": {},
   "source": [
    "# Fungsi Utility: Normalisasi URL & Ambil Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize(url):\n",
    "    # Normalisasi URL supaya tidak ada parameter yang bikin duplikat\n",
    "    p = urlparse(url)\n",
    "    return urlunparse((p.scheme or \"https\", p.netloc, p.path.rstrip('/'), \"\", \"\", \"\"))\n",
    "\n",
    "def first_text(soup, selectors):\n",
    "    # Ambil teks pertama yang cocok dari list CSS selector\n",
    "    for sel in selectors:\n",
    "        nodes = soup.select(sel)\n",
    "        if nodes:\n",
    "            return \" \".join([n.get_text(strip=True) for n in nodes])\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790fce7",
   "metadata": {},
   "source": [
    "# Variabel untuk Cegah Duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34839645",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_urls = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de979a35",
   "metadata": {},
   "source": [
    "# Fungsi Parsing Detail Berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4441b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news_detail(url, default_category):\n",
    "    try:\n",
    "        # Request detail berita\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"[ERROR] status {res.status_code} for {url}\")\n",
    "            return None\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Ambil canonical URL\n",
    "        canon_tag = soup.select_one('link[rel=\"canonical\"]')\n",
    "        final_url = canon_tag['href'] if canon_tag and canon_tag.get('href') else res.url\n",
    "        url_key = canonicalize(final_url)\n",
    "        if url_key in seen_urls:\n",
    "            return None\n",
    "        seen_urls.add(url_key)\n",
    "\n",
    "        # Judul berita\n",
    "        title = first_text(soup, [\"h1.read__title\", \"h1.article__title\", \"h1.title\"])\n",
    "        if not title:\n",
    "            m = soup.find('meta', property='og:title') or soup.find('meta', attrs={'name': 'title'})\n",
    "            title = m['content'] if m and m.get('content') else \"\"\n",
    "\n",
    "        # Isi berita\n",
    "        content = first_text(soup, [\n",
    "            \"div.read__content p\",\n",
    "            \"div.article__content p\",\n",
    "            \"div.detail_text p\",\n",
    "            \"div.article__lead p\",\n",
    "            \"div._article_content p\"\n",
    "        ])\n",
    "        if not content:\n",
    "            m = soup.find('meta', property='og:description') or soup.find('meta', attrs={'name': 'description'})\n",
    "            content = m['content'] if m and m.get('content') else \"\"\n",
    "\n",
    "        # Kategori (ambil breadcrumb jika ada, fallback ke default_category)\n",
    "        breadcrumb = [a.get_text(strip=True) for a in soup.select(\"a.breadcrumb__link, span.breadcrumb__link\")]\n",
    "        detected_kategori = breadcrumb[-1] if breadcrumb else default_category\n",
    "\n",
    "        return {\n",
    "            \"id\": str(uuid.uuid4()),        # ID unik\n",
    "            \"judul\": title,                 # Judul berita\n",
    "            \"isi\": content,                 # Isi berita\n",
    "            \"kategori\": default_category,   # Kategori awal (hardcode)\n",
    "            \"detected_kategori\": detected_kategori, # Kategori dari breadcrumb\n",
    "            \"url\": final_url                # URL canonical\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR parsing] {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950e929",
   "metadata": {},
   "source": [
    "# Fungsi Crawling per Kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f07dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_category(name, base_url, max_news_per_page=None, max_pages=20):\n",
    "    print(f\"[CRAWL] {name} — {base_url}\")\n",
    "    news_list = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        if max_pages and page > max_pages:\n",
    "            break\n",
    "\n",
    "        # URL pagination\n",
    "        page_url = f\"{base_url}?page={page}\"\n",
    "        print(f\"  [PAGE {page}] {page_url}\")\n",
    "        res = requests.get(page_url, headers=headers, timeout=10)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"   [ERROR] Can't access {page_url}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Cari semua link berita\n",
    "        anchors = soup.select(\"h3.article__title a, h4.article__title a, article a\")\n",
    "        if not anchors:\n",
    "            print(\"   [INFO] No links found, stop.\")\n",
    "            break\n",
    "\n",
    "        # Filter duplikat\n",
    "        hrefs = []\n",
    "        for a in anchors:\n",
    "            href = a.get(\"href\")\n",
    "            if not href:\n",
    "                continue\n",
    "            full = urljoin(base_url, href)\n",
    "            key = canonicalize(full)\n",
    "            if key not in seen_urls and key not in hrefs:\n",
    "                hrefs.append(full)\n",
    "\n",
    "        print(f\"   → Found {len(hrefs)} unique links on page {page}\")\n",
    "\n",
    "        # Ambil detail berita satu per satu\n",
    "        for idx, link in enumerate(hrefs):\n",
    "            if max_news_per_page and idx >= max_news_per_page:\n",
    "                break\n",
    "            print(f\"     - Fetching {idx+1}: {link}\")\n",
    "            news = parse_news_detail(link, name)\n",
    "            if news:\n",
    "                news_list.append(news)\n",
    "            time.sleep(1)  # delay 1 detik\n",
    "\n",
    "        page += 1\n",
    "    return news_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39875d50",
   "metadata": {},
   "source": [
    "# Hasil Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd46be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CRAWL] Nasional — https://nasional.kompas.com/\n",
      "  [PAGE 1] https://nasional.kompas.com/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] No links found, stop.\n",
      "[CRAWL] Ekonomi — https://money.kompas.com/\n",
      "  [PAGE 1] https://money.kompas.com/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 1 unique links on page 1\n",
      "     - Fetching 1: https://video.kompas.com/watch/1873974/cara-klaim-diskon-tambah-daya-listrik-pln-50-persen-september-2025?source=KOMPASCOM&position=money_terkini__player_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [PAGE 2] https://money.kompas.com/?page=2\n",
      "   → Found 0 unique links on page 2\n",
      "  [PAGE 3] https://money.kompas.com/?page=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 3\n",
      "  [PAGE 4] https://money.kompas.com/?page=4\n",
      "   → Found 0 unique links on page 4\n",
      "  [PAGE 5] https://money.kompas.com/?page=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 5\n",
      "  [PAGE 6] https://money.kompas.com/?page=6\n",
      "   → Found 0 unique links on page 6\n",
      "  [PAGE 7] https://money.kompas.com/?page=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 7\n",
      "  [PAGE 8] https://money.kompas.com/?page=8\n",
      "   → Found 0 unique links on page 8\n",
      "  [PAGE 9] https://money.kompas.com/?page=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 9\n",
      "  [PAGE 10] https://money.kompas.com/?page=10\n",
      "   → Found 0 unique links on page 10\n",
      "  [PAGE 11] https://money.kompas.com/?page=11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 11\n",
      "  [PAGE 12] https://money.kompas.com/?page=12\n",
      "   → Found 0 unique links on page 12\n",
      "  [PAGE 13] https://money.kompas.com/?page=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 13\n",
      "  [PAGE 14] https://money.kompas.com/?page=14\n",
      "   → Found 0 unique links on page 14\n",
      "  [PAGE 15] https://money.kompas.com/?page=15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 15\n",
      "  [PAGE 16] https://money.kompas.com/?page=16\n",
      "   → Found 0 unique links on page 16\n",
      "  [PAGE 17] https://money.kompas.com/?page=17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 17\n",
      "  [PAGE 18] https://money.kompas.com/?page=18\n",
      "   → Found 0 unique links on page 18\n",
      "  [PAGE 19] https://money.kompas.com/?page=19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 19\n",
      "  [PAGE 20] https://money.kompas.com/?page=20\n",
      "   → Found 0 unique links on page 20\n",
      "[CRAWL] Tekno — https://tekno.kompas.com/\n",
      "  [PAGE 1] https://tekno.kompas.com/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 29 unique links on page 1\n",
      "     - Fetching 1: https://tekno.kompas.com/read/2025/09/11/10070037/iphone-17-baru-punya-fitur-yang-sudah-ada-di-hp-android-sejak-2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 2: https://tekno.kompas.com/read/2025/09/11/09234927/startup-italia-bending-spoons-caplok-vimeo-senilai-rp-227-triliun\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 3: https://tekno.kompas.com/read/2025/09/11/09020017/oppo-a6-gt-5g-resmi-meluncur-dengan-baterai-7.000-mah-dan-ram-12-gb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 4: https://tekno.kompas.com/read/2025/09/10/14410087/ketika-layar-120-hz-baru-masuk-iphone-17-hp-android-sudah-8-tahun-lalu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 5: https://tekno.kompas.com/read/2025/09/11/08010017/foto-polaroid-gemini-ai-dipeluk-idol-k-pop-viral-ini-prompt-untuk-membuatnya\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 6: https://tekno.kompas.com/galeri/detail/557/Unboxing.dan.Hands-on.Infinix.Hot.60.Pro.Plus.Enteng.Tipis.seperti.Tak.Bawa.HP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 7: https://tekno.kompas.com/galeri/detail/556/Membuka.Kotak.Kemasan.Oppo.Reno.14.Pro.5G.yang.Punya.Desain.Baru\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 8: https://tekno.kompas.com/galeri/detail/555/Unboxing.HP.Tipis.Samsung.Galaxy.S25.Edge.di.Taipei\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 9: http://tekno.kompas.com/read/2025/09/10/08030077/lenovo-rilis-monitor-5k-lengkung-hemat-daya-thinkvision-p40wd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 10: http://tekno.kompas.com/read/2025/09/09/16420027/lenovo-rilis-flicklift-edit-foto-di-laptop-tak-perlu-photoshop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 11: http://tekno.kompas.com/read/2025/09/09/16080017/lenovo-rilis-loq-tower-26adr10-pc-gaming-dengan-panel-transparan-dan-futuristik\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 12: https://tekno.kompas.com/read/2025/09/09/19030087/riset-openai-ungkap-penyebab-chatbot-sering-halusinasi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 13: https://tekno.kompas.com/read/2025/09/10/11020087/pre-order-iphone-17-dibuka-12-september-di-singapura-kapan-indonesia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 14: https://tekno.kompas.com/read/2025/09/11/07000097/genshin-impact-6.0-dirilis-bawa-area-nod-krai-dan-karakter-baru-lauma-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 15: https://tekno.kompas.com/read/2025/09/08/11450007/saat-china-pamer-internet-10g-pertama-di-dunia-kecepatannya-hampir-10-gbps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 16: https://tekno.kompas.com/read/2025/09/10/12350017/iphone-17-rilis-harga-iphone-16-di-indonesia-turun-hingga-rp-3-jutaan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 17: https://tekno.kompas.com/read/2025/09/10/14130007/keluh-kesah-pemilik-infinix-gt-30-pro-kena-bug-reset-otomatis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 18: https://tekno.kompas.com/read/2025/09/10/19080037/oppo-a6i-meluncur-hp-murah-dengan-material-kuat-dan-baterai-besar-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 19: https://tekno.kompas.com/read/2025/09/10/18080027/hp-honor-play-10t-resmi-dengan-baterai-7.000-mah-harga-rp-2-jutaan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 20: https://tekno.kompas.com/read/2025/09/10/17350097/cara-cek-masa-aktif-telkomsel-via-online-dan-offline-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 21: https://tekno.kompas.com/read/2025/09/10/17030027/tampang-xiaomi-16-pro-max-tertangkap-kamera-punya-modul-yang-tidak-biasa-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 22: https://tekno.kompas.com/read/2025/09/10/16310037/bocoran-hp-realme-gt-8-pro-punya-modul-kamera-unik\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m hasil = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kategori, url \u001b[38;5;129;01min\u001b[39;00m category_urls.items():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     hasil.extend(\u001b[43mcrawl_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkategori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_news_per_page\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m)  \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Simpan hasil ke DataFrame\u001b[39;00m\n\u001b[32m      7\u001b[39m df = pd.DataFrame(hasil)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mcrawl_category\u001b[39m\u001b[34m(name, base_url, max_news_per_page, max_pages)\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m news:\n\u001b[32m     44\u001b[39m             news_list.append(news)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# delay 1 detik\u001b[39;00m\n\u001b[32m     47\u001b[39m     page += \u001b[32m1\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m news_list\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    hasil = []\n",
    "    for kategori, url in category_urls.items():\n",
    "        hasil.extend(crawl_category(kategori, url, max_news_per_page=None, max_pages=20))  \n",
    "\n",
    "    # Simpan hasil ke DataFrame\n",
    "    df = pd.DataFrame(hasil)\n",
    "    df = df.drop_duplicates(subset=['url'])  # hapus duplikat\n",
    "    df.to_csv(\"hasil_crawling_kompas.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[DONE] Total {len(df)} berita disimpan ke hasil_crawling_kompas.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}