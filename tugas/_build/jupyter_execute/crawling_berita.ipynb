{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00267db",
   "metadata": {},
   "source": [
    "# Crawling Berita Kompas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea435468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, uuid, time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse, urlunparse\n",
    "import pandas as pd\n",
    "\n",
    "# Header untuk menyamarkan request agar dianggap seperti browser biasa\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc2337c",
   "metadata": {},
   "source": [
    "# Daftar Kategori berita yang akan di crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910ab210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambah kategori supaya data lebih banyak\n",
    "category_urls = {\n",
    "    \"Nasional\": \"https://nasional.kompas.com/\",\n",
    "    \"Ekonomi\": \"https://money.kompas.com/\",\n",
    "    \"Tekno\": \"https://tekno.kompas.com/\",\n",
    "    \"Otomotif\": \"https://otomotif.kompas.com/\",\n",
    "    \"Health\": \"https://health.kompas.com/\",\n",
    "    \"Edukasi\": \"https://edukasi.kompas.com/\",\n",
    "    \"Bola\": \"https://bola.kompas.com/\",\n",
    "    \"Entertainment\": \"https://entertainment.kompas.com/\",\n",
    "    \"Lifestyle\": \"https://lifestyle.kompas.com/\",\n",
    "    \"Travel\": \"https://travel.kompas.com/\",\n",
    "    \"Internasional\": \"https://internasional.kompas.com/\",\n",
    "    \"Properti\": \"https://properti.kompas.com/\",\n",
    "    \"Sains\": \"https://sains.kompas.com/\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc192e25",
   "metadata": {},
   "source": [
    "# Fungsi Utility: Normalisasi URL & Ambil Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize(url):\n",
    "    # Normalisasi URL supaya tidak ada parameter yang bikin duplikat\n",
    "    p = urlparse(url)\n",
    "    return urlunparse((p.scheme or \"https\", p.netloc, p.path.rstrip('/'), \"\", \"\", \"\"))\n",
    "\n",
    "def first_text(soup, selectors):\n",
    "    # Ambil teks pertama yang cocok dari list CSS selector\n",
    "    for sel in selectors:\n",
    "        nodes = soup.select(sel)\n",
    "        if nodes:\n",
    "            return \" \".join([n.get_text(strip=True) for n in nodes])\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790fce7",
   "metadata": {},
   "source": [
    "# Variabel untuk Cegah Duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34839645",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_urls = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de979a35",
   "metadata": {},
   "source": [
    "# Fungsi Parsing Detail Berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4441b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news_detail(url, default_category):\n",
    "    try:\n",
    "        # Request detail berita\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"[ERROR] status {res.status_code} for {url}\")\n",
    "            return None\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Ambil canonical URL\n",
    "        canon_tag = soup.select_one('link[rel=\"canonical\"]')\n",
    "        final_url = canon_tag['href'] if canon_tag and canon_tag.get('href') else res.url\n",
    "        url_key = canonicalize(final_url)\n",
    "        if url_key in seen_urls:\n",
    "            return None\n",
    "        seen_urls.add(url_key)\n",
    "\n",
    "        # Judul berita\n",
    "        title = first_text(soup, [\"h1.read__title\", \"h1.article__title\", \"h1.title\"])\n",
    "        if not title:\n",
    "            m = soup.find('meta', property='og:title') or soup.find('meta', attrs={'name': 'title'})\n",
    "            title = m['content'] if m and m.get('content') else \"\"\n",
    "\n",
    "        # Isi berita\n",
    "        content = first_text(soup, [\n",
    "            \"div.read__content p\",\n",
    "            \"div.article__content p\",\n",
    "            \"div.detail_text p\",\n",
    "            \"div.article__lead p\",\n",
    "            \"div._article_content p\"\n",
    "        ])\n",
    "        if not content:\n",
    "            m = soup.find('meta', property='og:description') or soup.find('meta', attrs={'name': 'description'})\n",
    "            content = m['content'] if m and m.get('content') else \"\"\n",
    "\n",
    "        # Kategori (ambil breadcrumb jika ada, fallback ke default_category)\n",
    "        breadcrumb = [a.get_text(strip=True) for a in soup.select(\"a.breadcrumb__link, span.breadcrumb__link\")]\n",
    "        detected_kategori = breadcrumb[-1] if breadcrumb else default_category\n",
    "\n",
    "        return {\n",
    "            \"id\": str(uuid.uuid4()),        # ID unik\n",
    "            \"judul\": title,                 # Judul berita\n",
    "            \"isi\": content,                 # Isi berita\n",
    "            \"kategori\": default_category,   # Kategori awal (hardcode)\n",
    "            \"detected_kategori\": detected_kategori, # Kategori dari breadcrumb\n",
    "            \"url\": final_url                # URL canonical\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR parsing] {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950e929",
   "metadata": {},
   "source": [
    "# Fungsi Crawling per Kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f07dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_category(name, base_url, max_news_per_page=None, max_pages=20):\n",
    "    print(f\"[CRAWL] {name} — {base_url}\")\n",
    "    news_list = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        if max_pages and page > max_pages:\n",
    "            break\n",
    "\n",
    "        # URL pagination\n",
    "        page_url = f\"{base_url}?page={page}\"\n",
    "        print(f\"  [PAGE {page}] {page_url}\")\n",
    "        res = requests.get(page_url, headers=headers, timeout=10)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"   [ERROR] Can't access {page_url}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Cari semua link berita\n",
    "        anchors = soup.select(\"h3.article__title a, h4.article__title a, article a\")\n",
    "        if not anchors:\n",
    "            print(\"   [INFO] No links found, stop.\")\n",
    "            break\n",
    "\n",
    "        # Filter duplikat\n",
    "        hrefs = []\n",
    "        for a in anchors:\n",
    "            href = a.get(\"href\")\n",
    "            if not href:\n",
    "                continue\n",
    "            full = urljoin(base_url, href)\n",
    "            key = canonicalize(full)\n",
    "            if key not in seen_urls and key not in hrefs:\n",
    "                hrefs.append(full)\n",
    "\n",
    "        print(f\"   → Found {len(hrefs)} unique links on page {page}\")\n",
    "\n",
    "        # Ambil detail berita satu per satu\n",
    "        for idx, link in enumerate(hrefs):\n",
    "            if max_news_per_page and idx >= max_news_per_page:\n",
    "                break\n",
    "            print(f\"     - Fetching {idx+1}: {link}\")\n",
    "            news = parse_news_detail(link, name)\n",
    "            if news:\n",
    "                news_list.append(news)\n",
    "            time.sleep(1)  # delay 1 detik\n",
    "\n",
    "        page += 1\n",
    "    return news_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39875d50",
   "metadata": {},
   "source": [
    "# Hasil Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd46be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CRAWL] Nasional — https://nasional.kompas.com/\n",
      "  [PAGE 1] https://nasional.kompas.com/?page=1\n",
      "   [INFO] No links found, stop.\n",
      "[CRAWL] Ekonomi — https://money.kompas.com/\n",
      "  [PAGE 1] https://money.kompas.com/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 1 unique links on page 1\n",
      "     - Fetching 1: https://video.kompas.com/watch/1873974/cara-klaim-diskon-tambah-daya-listrik-pln-50-persen-september-2025?source=KOMPASCOM&position=money_terkini__player_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [PAGE 2] https://money.kompas.com/?page=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 2\n",
      "  [PAGE 3] https://money.kompas.com/?page=3\n",
      "   → Found 0 unique links on page 3\n",
      "  [PAGE 4] https://money.kompas.com/?page=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 4\n",
      "  [PAGE 5] https://money.kompas.com/?page=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 5\n",
      "  [PAGE 6] https://money.kompas.com/?page=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 6\n",
      "  [PAGE 7] https://money.kompas.com/?page=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 7\n",
      "  [PAGE 8] https://money.kompas.com/?page=8\n",
      "   → Found 0 unique links on page 8\n",
      "  [PAGE 9] https://money.kompas.com/?page=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 9\n",
      "  [PAGE 10] https://money.kompas.com/?page=10\n",
      "   → Found 0 unique links on page 10\n",
      "  [PAGE 11] https://money.kompas.com/?page=11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 11\n",
      "  [PAGE 12] https://money.kompas.com/?page=12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 12\n",
      "  [PAGE 13] https://money.kompas.com/?page=13\n",
      "   → Found 0 unique links on page 13\n",
      "  [PAGE 14] https://money.kompas.com/?page=14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 14\n",
      "  [PAGE 15] https://money.kompas.com/?page=15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 15\n",
      "  [PAGE 16] https://money.kompas.com/?page=16\n",
      "   → Found 0 unique links on page 16\n",
      "  [PAGE 17] https://money.kompas.com/?page=17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 17\n",
      "  [PAGE 18] https://money.kompas.com/?page=18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 18\n",
      "  [PAGE 19] https://money.kompas.com/?page=19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 19\n",
      "  [PAGE 20] https://money.kompas.com/?page=20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 0 unique links on page 20\n",
      "[CRAWL] Tekno — https://tekno.kompas.com/\n",
      "  [PAGE 1] https://tekno.kompas.com/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Found 29 unique links on page 1\n",
      "     - Fetching 1: https://tekno.kompas.com/read/2025/09/11/10070037/iphone-17-baru-punya-fitur-yang-sudah-ada-di-hp-android-sejak-2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 2: https://tekno.kompas.com/read/2025/09/11/09234927/startup-italia-bending-spoons-caplok-vimeo-senilai-rp-227-triliun\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 3: https://tekno.kompas.com/read/2025/09/11/09020017/oppo-a6-gt-5g-resmi-meluncur-dengan-baterai-7.000-mah-dan-ram-12-gb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 4: https://tekno.kompas.com/read/2025/09/10/14410087/ketika-layar-120-hz-baru-masuk-iphone-17-hp-android-sudah-8-tahun-lalu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 5: https://tekno.kompas.com/read/2025/09/11/08010017/foto-polaroid-gemini-ai-dipeluk-idol-k-pop-viral-ini-prompt-untuk-membuatnya\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 6: https://tekno.kompas.com/galeri/detail/557/Unboxing.dan.Hands-on.Infinix.Hot.60.Pro.Plus.Enteng.Tipis.seperti.Tak.Bawa.HP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 7: https://tekno.kompas.com/galeri/detail/556/Membuka.Kotak.Kemasan.Oppo.Reno.14.Pro.5G.yang.Punya.Desain.Baru\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 8: https://tekno.kompas.com/galeri/detail/555/Unboxing.HP.Tipis.Samsung.Galaxy.S25.Edge.di.Taipei\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 9: http://tekno.kompas.com/read/2025/09/10/08030077/lenovo-rilis-monitor-5k-lengkung-hemat-daya-thinkvision-p40wd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fetching 10: http://tekno.kompas.com/read/2025/09/09/16420027/lenovo-rilis-flicklift-edit-foto-di-laptop-tak-perlu-photoshop\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m hasil = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kategori, url \u001b[38;5;129;01min\u001b[39;00m category_urls.items():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     hasil.extend(\u001b[43mcrawl_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkategori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_news_per_page\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m)  \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Simpan hasil ke DataFrame\u001b[39;00m\n\u001b[32m      7\u001b[39m df = pd.DataFrame(hasil)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mcrawl_category\u001b[39m\u001b[34m(name, base_url, max_news_per_page, max_pages)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m     - Fetching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m news = \u001b[43mparse_news_detail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m news:\n\u001b[32m     44\u001b[39m     news_list.append(news)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mparse_news_detail\u001b[39m\u001b[34m(url, default_category)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_news_detail\u001b[39m(url, default_category):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      3\u001b[39m         \u001b[38;5;66;03m# Request detail berita\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         res = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m res.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m      6\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[ERROR] status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:724\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[32m    722\u001b[39m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[32m    723\u001b[39m     gen = \u001b[38;5;28mself\u001b[39m.resolve_redirects(r, request, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     history = \u001b[43m[\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    726\u001b[39m     history = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:265\u001b[39m, in \u001b[36mSessionRedirectMixin.resolve_redirects\u001b[39m\u001b[34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m.cookies, prepared_request, resp.raw)\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/http/client.py:1419\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1418\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/ssl.py:1253\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1251\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1252\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    hasil = []\n",
    "    for kategori, url in category_urls.items():\n",
    "        hasil.extend(crawl_category(kategori, url, max_news_per_page=None, max_pages=20))  \n",
    "\n",
    "    # Simpan hasil ke DataFrame\n",
    "    df = pd.DataFrame(hasil)\n",
    "    df = df.drop_duplicates(subset=['url'])  # hapus duplikat\n",
    "    df.to_csv(\"hasil_crawling_kompas.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[DONE] Total {len(df)} berita disimpan ke hasil_crawling_kompas.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}